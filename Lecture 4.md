## Bayesian Neural Networks (BNNs) ðŸ§ 

### Flipout vs. BBB - Regression ðŸ“Š

When comparing **Bayes by Backprop (BBB)** and **Flipout** in regression tasks, **Flipout** exhibits reduced variance and converges faster with less noise compared to **BBB**.

### Architectural Considerations ðŸ—ï¸

- Bayesian NNs don't need to use all layers with weight distributions (**Bayesian Layers**).
- The concept of **Bayesian layers** also applies to other methods like **MC-Dropout/DropConnect, Ensembling**, etc.
- Adjusting the number of Bayesian layers affects the trade-off between computation and uncertainty quality.
    - Fewer layers: faster model, poor uncertainty
    - More layers: slower model, high-quality uncertainty
- The number of Bayesian layers primarily influences **epistemic uncertainty**.

### Making Predictions ðŸŽ¯

To make predictions with a **VI-approximate Bayesian neural network**, the **Monte Carlo approximation** is used to the **Predictive Posterior Distribution** with M samples:

P(yâˆ£x)â‰ˆ1Mâˆ‘iMP(yâˆ£wi0,x)P(wi0âˆ£x)P(yâˆ£x)â‰ˆM1â€‹âˆ‘iMâ€‹P(yâˆ£wi0â€‹â€‹,x)P(wi0â€‹â€‹âˆ£x) where wi0âˆ¼P(wâˆ£D)wi0â€‹â€‹âˆ¼P(wâˆ£D)

This involves sampling the posterior distribution of the weights P(wâˆ£x)P(wâˆ£x) to produce weights ww, which are used to make a forward pass (P(yâˆ£wi,x)P(yâˆ£wiâ€‹,x)), and then taking a weighted average.

A common approximation is:

P(yâˆ£x)â‰ˆ1Mâˆ‘iMP(yâˆ£wi0,x)P(yâˆ£x)â‰ˆM1â€‹âˆ‘iMâ€‹P(yâˆ£wi0â€‹â€‹,x) where wi0âˆ¼P(wâˆ£D)wi0â€‹â€‹âˆ¼P(wâˆ£D)

This simplified version doesn't weight using the weight posterior, useful when weight probabilities P(wi0âˆ£x)P(wi0â€‹â€‹âˆ£x) cannot be directly computed.

## Uncertainty Disentanglement ðŸ§©

### Concept ðŸ’¡

> Predictive uncertainty is usually a combination of **aleatoric** and **epistemic uncertainty**.

PredictiveÂ Uncertainty=Epistemic+AleatoricPredictiveÂ Uncertainty=Epistemic+Aleatoric

The goal is to obtain these uncertainties separately and train models accordingly.

### Applications Benefiting from Disentanglement ðŸš€

- **Out-of-Distribution Detection**: requires only **epistemic uncertainty**.
- **Measurements from Noisy Ground Truth**: model should distinguish between measurement noise (**aleatoric uncertainty**) and model uncertainty (**epistemic uncertainty**).
- **Active Learning**: needs accurate **epistemic uncertainty** estimates, ignoring **aleatoric uncertainty**, to select which samples to label next.

### Uncertainty Disentanglement - Regression ðŸ“ˆ

- **Aleatoric Uncertainty**: can be estimated using the **Gaussian Negative Log-Likelihood** and a **Two-Head Model**.
- **Epistemic Uncertainty**: can be produced using UQ methods like **MC-Dropout/DropConnect**, **Ensembles**, **Bayes by Backprop**, or **Flipout**.

Combining both sources of uncertainty, we use a **Gaussian mixture model** (similar to an Ensemble):

p(yâˆ£x)âˆ¼N(Î¼âˆ—(x),Ïƒâˆ—2(x))p(yâˆ£x)âˆ¼N(Î¼âˆ—â€‹(x),Ïƒâˆ—2â€‹(x))

where

Î¼âˆ—(x)=1Mâˆ‘iÎ¼i(x)Î¼âˆ—â€‹(x)=M1â€‹âˆ‘iâ€‹Î¼iâ€‹(x)

Ïƒâˆ—2(x)=1Mâˆ‘i(Ïƒi2(x)+Î¼i2(x))âˆ’Î¼âˆ—2(x)Ïƒâˆ—2â€‹(x)=M1â€‹âˆ‘iâ€‹(Ïƒi2â€‹(x)+Î¼i2â€‹(x))âˆ’Î¼âˆ—2â€‹(x)

Here, $i$ iterates through the samples/ensembles, and $M$ is the number of samples or ensemble members.

#### Deeper Look at Variance ðŸ”Ž

The variance $ \sigma^2*$ can be broken down:

Ïƒâˆ—2(x)=1Mâˆ‘iÏƒi2(x)+1Mâˆ‘iÎ¼i2(x)âˆ’Î¼âˆ—2(x)Ïƒâˆ—2â€‹(x)=M1â€‹âˆ‘iâ€‹Ïƒi2â€‹(x)+M1â€‹âˆ‘iâ€‹Î¼i2â€‹(x)âˆ’Î¼âˆ—2â€‹(x)

=Ei[Ïƒi2(x)]+Ei[Î¼i2(x)]âˆ’Ei[Î¼i(x)]2=Eiâ€‹[Ïƒi2â€‹(x)]+Eiâ€‹[Î¼i2â€‹(x)]âˆ’Eiâ€‹[Î¼iâ€‹(x)]2

=Ei[Ïƒi2(x)]+Vari[Î¼i(x)]=Eiâ€‹[Ïƒi2â€‹(x)]+Variâ€‹[Î¼iâ€‹(x)]

AleatoricÂ Uncertainty+EpistemicÂ UncertaintyAleatoricÂ Uncertainty+EpistemicÂ Uncertainty

- **Aleatoric uncertainty**: mean of the per-sample/ensemble variances.
- **Epistemic uncertainty**: variance of the per-sample/ensemble means.

#### Intuition ðŸ’­

- **Aleatoric Uncertainty**: combines all variances into a single variance.
- **Epistemic Uncertainty**: variation or disagreement between models/samples; if all means are the same, the model(s) is very confident; if means differ, the model(s) disagree, indicating epistemic uncertainty.



## Evaluation of Uncertainty Quantification ðŸ“Š

### Concept ðŸ’¡

Specific methods are required to evaluate the quality of uncertainty produced by models. Standard evaluation formulations generally don't consider uncertainty at the output.

### Importance of Uncertainty Evaluation Methods ðŸŒŸ

> Error and misclassification should be proportional to output uncertainty made by a model.

This makes output uncertainty useful for the end user.

### Warning âš ï¸

Selection of **loss functions** and **metrics** is crucial. Losses should be selected according to the task, and metrics should be selected based on the desired knowledge and performance measurements.

### Learning Performance ðŸ“ˆ

||Definition|
|---|---|
|**Losses**|Objective function guiding learning; defines the task and quality of solutions; usually differentiable.|
|**Metrics**|Measurements of quality to evaluate learning; usually non-differentiable. Losses can be used as metrics.|

### Probabilistic Classifiers ðŸ¤–

Most classifiers output a probability vector $p$ of length $C$. The class integer index $c$ can be recovered by:

c=argmaxipic=argmaxiâ€‹piâ€‹

For binary classification, only a single probability is required:

f(x)=P(y=1)=1âˆ’P(y=0)f(x)=P(y=1)=1âˆ’P(y=0)

### Obtaining Confidences ðŸ¤

||Description|
|---|---|
|**Classification**||
|Confidence|$= max_i p_i$|
|Entropy|$h = -\sum_i p_i log\ p_i$, where low entropy is high confidence, and high entropy is low confidence|
|**Regression**||
|Confidence|Standard deviation (square root of variance) from an output head.|

### Loss Functions - Classification ðŸ“‰

|Loss|Description|
|---|---|
|**Categorical Cross-Entropy**|Used for multi-class classification with one-hot encoded labels $y_c$ and class probabilities $ \hat{y}_c$ summing to 1. L(y,y^)=âˆ’âˆ‘iâˆ‘cyiclog(y^ic)L(y,y^â€‹)=âˆ’âˆ‘iâ€‹âˆ‘câ€‹yicâ€‹log(y^â€‹icâ€‹)|
|**Binary Cross-Entropy**|Used for binary classification with labels yiâˆˆ0,1yiâ€‹âˆˆ0,1. L(y,y^)=âˆ’âˆ‘i[yilog(y^i)+(1âˆ’yi)log(1âˆ’y^i)]L(y,y^â€‹)=âˆ’âˆ‘iâ€‹[yiâ€‹log(y^â€‹iâ€‹)+(1âˆ’yiâ€‹)log(1âˆ’y^â€‹iâ€‹)]|

### Loss Functions - Negative Log-Likelihood (NLL) ðŸ“‰

For regression with uncertainty, NLL is commonly used:

logÂ p(yâˆ£x)=âˆ‘i(Î¼(xi)âˆ’yi)22Ïƒ2(xi)+12log(2Ï€Ïƒ2(xi))+ClogÂ p(yâˆ£x)=âˆ‘iâ€‹2Ïƒ2(xiâ€‹)(Î¼(xiâ€‹)âˆ’yiâ€‹)2â€‹+21â€‹log(2Ï€Ïƒ2(xiâ€‹))+C

The model outputs a mean $ \mu(x)$ and variance $ \sigma^2(x)$. Uncertainty (large variance) reduces the impact of squared error. This assumes the model outputs parameters of a Gaussian distribution.

### Other Loss Functions ðŸ“‰

|Loss|Description|
|---|---|
|**KL Divergence**|Distance measure between probability distributions $p$ and $q$. Cross-Entropy is a simplified version.|

### Loss Functions with Uncertainty ðŸ“‰

- **Cross Entropy**: Special case of NLL for classification, considers probabilities/confidences of the correct class.
- **Gaussian NLL**: Special case of NLL for regression with Gaussian distributed output. Models uncertainty through the variance output.
- **KL Divergence**: Measures distance between probability distributions, implicitly modeling uncertainty.

### Reproducibility â™»ï¸

When training the same neural network architecture on the same dataset five times:

- Each model will be unique due to different weight values.
- Predictions will differ.
- Aleatoric Uncertainty should be similar.
- Epistemic Uncertainty will vary.

This assumes the model is properly trained and converged.

### Interaction Between Aleatoric and Epistemic Uncertainty ðŸ¤

They interact when both are predicted by a model:

- **Aleatoric Uncertainty**: has a degree of its own Epistemic Uncertainty due to estimating it with a model.
- **Epistemic Uncertainty**: directly related to the model with no additional interaction.

### Proper Scoring Rules ðŸ¥‡

> A scoring rule is a function $S(p,(y,x))$ that evaluates the quality of a predicted probability distribution $p(y|x)$ relative to an event $y \sim q(y|x)$, where $q(y|x)$ is the true distribution.

The expected scoring rule is given by:

S(p,q)=âˆ«q(y,x)S(p,(y,x))dydxS(p,q)=âˆ«q(y,x)S(p,(y,x))dydx

A **proper scoring rule** satisfies:

S(p,q)<=S(q,q)S(p,q)<=S(q,q)

Equality holds only if $p(y|x) = q(y|x)$ for all $p$ and $q$. Best value is obtained by predicting the true distribution $q$.

#### Examples of Proper Scoring Rules âœ…

- Log-loss: $S(p, (y, x)) = log\ p(y|x)$
- Cross-entropy loss
- KL Divergence
- Brier score
- Gaussian Negative Log-Likelihood

#### Improper Scoring Rules âŒ

- Standard accuracy
- Mean squared error and mean absolute error
- Custom metrics using geometric means

#### What Does This Mean? ðŸ¤”

- **Proper scoring rules**: lead to predicting the true distribution.
- **Improper scoring rules**: can mislead and don't always lead to predicting the true distribution.

### Coverage - Regression ðŸŽ¯

Given confidence intervals $[l_i, u_i]$, coverage is computed as:

Cov(y,y^)=1Nâˆ‘i1[y^l<=yi<=y^h]Cov(y,y^â€‹)=N1â€‹âˆ‘iâ€‹1[y^â€‹lâ€‹<=yiâ€‹<=y^â€‹hâ€‹]

### Differential Entropy - Regression â™¾ï¸

Entropy extended to continuous distributions:

h(X)=âˆ«f(x)logÂ f(x)dxh(X)=âˆ«f(x)logÂ f(x)dx

For a Gaussian distribution, entropy is $ \frac{1}{2}log(2\pi\sigma^2) + 1$, depending only on the variance $ \sigma^2$.

### Brier Score - Classification ðŸ”¢

Mean squared error applied to output probabilities vs the target probability distribution:

Brier(y,y^)=1Nâˆ‘i(yiâˆ’y^i)2Brier(y,y^â€‹)=N1â€‹âˆ‘iâ€‹(yiâ€‹âˆ’y^â€‹iâ€‹)2

Measures how close predicted and true probabilities are.

### Entropy - Classification ðŸ“Š

Measurement of "information content" in a probability distribution. For classification:

H=âˆ’âˆ‘cP(xâˆ£c)logÂ P(xâˆ£c)H=âˆ’âˆ‘câ€‹P(xâˆ£c)logÂ P(xâˆ£c)

Where $c$ are the class indices $c \in [0, C-1]$. Uniform distribution maximizes entropy.